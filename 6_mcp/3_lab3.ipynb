{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to Week 6 Day 3!\n",
    "\n",
    "Let's experiment with a bunch more MCP Servers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace\n",
    "from agents.mcp import MCPServerStdio\n",
    "import os\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "from openai import AsyncOpenAI\n",
    "from agents import OpenAIChatCompletionsModel\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The first type of MCP Server: runs locally, everything local\n",
    "\n",
    "Here's a really interesting one: a knowledge-graph based memory.\n",
    "\n",
    "It's a persistent memory store of entities, observations about them, and relationships between them.\n",
    "\n",
    "https://github.com/modelcontextprotocol/servers/tree/main/src/memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='create_entities', title=None, description='Create new entities with observations and optional embeddings', inputSchema={'type': 'object', 'properties': {'entities': {'type': 'array', 'items': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'entityType': {'type': 'string'}, 'observations': {'type': 'array', 'items': {'type': 'string'}}, 'embedding': {'type': 'array', 'items': {'type': 'number'}, 'description': 'Optional vector embedding for similarity search'}}, 'required': ['name', 'entityType', 'observations']}}}, 'required': ['entities']}, outputSchema=None, annotations=None, meta=None),\n",
       " Tool(name='search_nodes', title=None, description='Search for entities and their relations using text or vector similarity', inputSchema={'type': 'object', 'properties': {'query': {'oneOf': [{'type': 'string', 'description': 'Text search query'}, {'type': 'array', 'items': {'type': 'number'}, 'description': 'Vector for similarity search'}]}}, 'required': ['query']}, outputSchema=None, annotations=None, meta=None),\n",
       " Tool(name='read_graph', title=None, description='Get recent entities and their relations', inputSchema={'type': 'object', 'properties': {}, 'required': []}, outputSchema=None, annotations=None, meta=None),\n",
       " Tool(name='create_relations', title=None, description='Create relations between entities', inputSchema={'type': 'object', 'properties': {'relations': {'type': 'array', 'items': {'type': 'object', 'properties': {'source': {'type': 'string'}, 'target': {'type': 'string'}, 'type': {'type': 'string'}}, 'required': ['source', 'target', 'type']}}}, 'required': ['relations']}, outputSchema=None, annotations=None, meta=None),\n",
       " Tool(name='delete_entity', title=None, description='Delete an entity and all its associated data (observations and relations)', inputSchema={'type': 'object', 'properties': {'name': {'type': 'string', 'description': 'Name of the entity to delete'}}, 'required': ['name']}, outputSchema=None, annotations=None, meta=None),\n",
       " Tool(name='delete_relation', title=None, description='Delete a specific relation between entities', inputSchema={'type': 'object', 'properties': {'source': {'type': 'string', 'description': 'Source entity name'}, 'target': {'type': 'string', 'description': 'Target entity name'}, 'type': {'type': 'string', 'description': 'Type of relation'}}, 'required': ['source', 'target', 'type']}, outputSchema=None, annotations=None, meta=None)]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"command\": \"npx\",\"args\": [\"-y\", \"mcp-memory-libsql\"],\"env\": {\"LIBSQL_URL\": \"file:./memory/ed.db\"}}\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "\n",
    "mcp_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You use your entity tools as a persistent memory to store and recall information about your conversations.\"\n",
    "request = \"My name's Ed. I'm an LLM engineer. I'm teaching a course about AI Agents, including the incredible MCP protocol. \\\n",
    "MCP is a protocol for connecting agents with tools, resources and prompt templates, and makes it easy to integrate AI agents with capabilities.\"\n",
    "# model = \"gpt-4.1-mini\"\n",
    "BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "MODEL_NAME='gemini-2.0-flash'\n",
    "\n",
    "gemini_client = AsyncOpenAI(base_url=BASE_URL, api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "custom_model = OpenAIChatCompletionsModel(model=MODEL_NAME, openai_client=gemini_client) \n",
    "model = custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "OK. I've stored the information about you and the MCP protocol.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is not set, skipping trace export\n",
      "OPENAI_API_KEY is not set, skipping trace export\n"
     ]
    }
   ],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I know you're Ed, and that you're an LLM engineer. I also know that you're teaching a course about AI Agents, and that you're teaching about the MCP protocol. Is there anything else I can help you with?\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, \"My name's Ed. What do you know about me?\")\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the trace:\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The 2nd type of MCP server - runs locally, calls a web service\n",
    "\n",
    "### Brave Search - apologies - this will need another API key! But it's free again.\n",
    "\n",
    "https://brave.com/search/api/\n",
    "\n",
    "Set up your account, and put your key in the .env under `BRAVE_API_KEY`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='brave_web_search', title=None, description='Performs a web search using the Brave Search API, ideal for general queries, news, articles, and online content. Use this for broad information gathering, recent events, or when you need diverse web sources. Supports pagination, content filtering, and freshness controls. Maximum 20 results per request, with offset for pagination. ', inputSchema={'type': 'object', 'properties': {'query': {'type': 'string', 'description': 'Search query (max 400 chars, 50 words)'}, 'count': {'type': 'number', 'description': 'Number of results (1-20, default 10)', 'default': 10}, 'offset': {'type': 'number', 'description': 'Pagination offset (max 9, default 0)', 'default': 0}}, 'required': ['query']}, outputSchema=None, annotations=None, meta=None),\n",
       " Tool(name='brave_local_search', title=None, description=\"Searches for local businesses and places using Brave's Local Search API. Best for queries related to physical locations, businesses, restaurants, services, etc. Returns detailed information including:\\n- Business names and addresses\\n- Ratings and review counts\\n- Phone numbers and opening hours\\nUse this when the query implies 'near me' or mentions specific locations. Automatically falls back to web search if no local results are found.\", inputSchema={'type': 'object', 'properties': {'query': {'type': 'string', 'description': \"Local search query (e.g. 'pizza near Central Park')\"}, 'count': {'type': 'number', 'description': 'Number of results (1-20, default 5)', 'default': 5}}, 'required': ['query']}, outputSchema=None, annotations=None, meta=None)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = {\"BRAVE_API_KEY\": os.getenv(\"BRAVE_API_KEY\")}\n",
    "params = {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-brave-search\"], \"env\": env}\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "\n",
    "mcp_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You are able to search the web for information and briefly summarize the takeaways.\"\n",
    "# request = f\"Please research the latest news on Amazon stock price and briefly summarize its outlook. \\\n",
    "# For context, the current date is {datetime.now().strftime('%Y-%m-%d')}\"\n",
    "request = \"What is the result lasted match between the Machester United and Manchester City ?\"\n",
    "model = custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Based on the search results, the last match between Manchester City and Manchester United that I found was on September 14, 2025, where Manchester City won 3-0 against Manchester United.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Trace] ID: trace_1790cb2537ba4ae6af5a66cfe1a1bc7a | Name: conversation\n",
      "🧠 Model Used: gemini-2.0-flash\n",
      "📥 Input Tokens: 190\n",
      "📤 Output Tokens: 17\n",
      "🙋 User Asked: What is the result lasted match between the Machester United and Manchester City ?\n",
      "🤖 Bot Replied: None\n",
      "🧠 Model Used: gemini-2.0-flash\n",
      "📥 Input Tokens: 533\n",
      "📤 Output Tokens: 44\n",
      "🙋 User Asked: {\"type\":\"text\",\"text\":\"Title: Manchester City vs Manchester United live score, H2H and lineups | Sofascore\\nDescription: You can also live stream this match through our betting partners or click on any links on Sofascore for a legal live stream.Event details: NAME: Manchester City - Manchester United · DATE: <strong>14 Sept 2025</strong> TIME: 15:30 UTC VENUE: Etihad Stadium, Manchester, England More details:Manchester City ...\\nURL: https://www.sofascore.com/football/match/manchester-united-manchester-city/rK\\n\\nTitle: Manchester City football club: record v Manchester United\\nDescription: <strong>Manchester</strong> <strong>City</strong> football club record against <strong>Manchester</strong> <strong>United</strong>, including all <strong>match</strong> details.\\nURL: https://www.11v11.com/teams/manchester-city/tab/opposingTeams/opposition/Manchester%20United/\\n\\nTitle: Manchester City 3-0 Manchester United: Premier League – as it happened | Premier League | The Guardian\\nDescription: A rampant Erling Haaland scored twice to give <strong>City</strong> a thumping win over their woebegone local rivals\\nURL: https://www.theguardian.com/football/live/2025/sep/14/manchester-city-v-manchester-united-premier-league-live\",\"annotations\":null,\"meta\":null}\n",
      "🤖 Bot Replied: Based on the search results, the last match between Manchester City and Manchester United that I found was on September 14, 2025, where Manchester City won 3-0 against Manchester United.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from agents.tracing.processors import ConsoleSpanExporter, BatchTraceProcessor, default_processor\n",
    "from agents.tracing.processor_interface import TracingExporter\n",
    "from agents.tracing.traces import Trace\n",
    "from agents.tracing.spans import Span\n",
    "from agents import Agent, Runner, trace , set_trace_processors\n",
    "\n",
    "\n",
    "class CustomConsoleSpanExporter(TracingExporter):\n",
    "    def export(self, items: list[Trace | Span]):\n",
    "        for item in items:\n",
    "            if isinstance(item, Trace):\n",
    "                print(f\"[Trace] ID: {item.trace_id} | Name: {item.name}\")\n",
    "            elif item.span_data.type == \"generation\":\n",
    "                usage = item.span_data.usage or {}\n",
    "                model = item.span_data.model\n",
    "                user_input = item.span_data.input or []\n",
    "                output = item.span_data.output or []\n",
    "\n",
    "                print(\"🧠 Model Used:\", model)\n",
    "                print(\"📥 Input Tokens:\", usage.get(\"input_tokens\", \"N/A\"))\n",
    "                print(\"📤 Output Tokens:\", usage.get(\"output_tokens\", \"N/A\"))\n",
    "\n",
    "                if user_input:\n",
    "                    print(\"🙋 User Asked:\", user_input[-1].get(\"content\", \"N/A\"))\n",
    "                if output:\n",
    "                    print(\"🤖 Bot Replied:\", output[0].get(\"content\", \"N/A\"))\n",
    "\n",
    "#Custom trace processor\n",
    "exporter = CustomConsoleSpanExporter()\n",
    "processor = BatchTraceProcessor(exporter)\n",
    "set_trace_processors([processor])\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=30) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As usual, check out the trace:\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And now the third type: running remotely\n",
    "\n",
    "It's actually really hard to find a \"remote MCP server\" aka \"hosted MCP server\" aka \"managed MCP server\".\n",
    "\n",
    "It's not a common model for using or sharing MCP servers, and there isn't a standard way to discover remote MCP servers.\n",
    "\n",
    "Anthropic lists some remote MCP servers, but these are for paid applications with business users:\n",
    "\n",
    "https://docs.anthropic.com/en/docs/agents-and-tools/remote-mcp-servers\n",
    "\n",
    "CloudFlare has tooling for you to create and deploy your own remote MCP servers, but this does not seem to be a common practice:\n",
    "\n",
    "https://developers.cloudflare.com/agents/guides/remote-mcp-server/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# And back to the 2nd type: the Polygon.io MCP Server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">PLEASE READ!!-</h2>\n",
    "            <span style=\"color:#ff7800;\">This service for financial market data has both a FREE plan and a PAID plan, and we can use either depending on your appetite.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NEW SECTION: Introducing polygon.io\n",
    "\n",
    "Polygon.io is a hugely popular financial data provider. It has a free plan and a paid plan. And it also has an MCP Server!\n",
    "\n",
    "First, read up on polygon.io on their excellent website, including looking at their pricing:\n",
    "\n",
    "https://polygon.io\n",
    "\n",
    "### Polygon.io Part 1: Polygon.io free service (the paid will be totally optional, of course!)\n",
    "\n",
    "1. Please sign up for polygon.io (top right)  \n",
    "2. Once signed in, please select \"Keys\" in the left hand navigation\n",
    "3. Press the blue \"New Key\" button\n",
    "4. Copy the key name\n",
    "5. Edit your .env file and add the row:\n",
    "\n",
    "`POLYGON_API_KEY=xxxx`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "polygon_api_key = os.getenv(\"POLYGON_API_KEY\")\n",
    "if not polygon_api_key:\n",
    "    print(\"POLYGON_API_KEY is not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreviousCloseAgg(ticker='AAPL', close=236.7, high=238.19, low=235.03, open=237, timestamp=1757966400000, volume=42699524.0, vwap=236.3383)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from polygon import RESTClient\n",
    "client = RESTClient(polygon_api_key)\n",
    "client.get_previous_close_agg(\"AAPL\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrapped into a python module that caches end of day prices\n",
    "\n",
    "I've made a python module `market.py` that uses this API to look up share prices.\n",
    "\n",
    "But the free API is quite heavily rate limited - so I've been a bit sneaky; when you ask for a share price, this function retrieves the entire end-of-day equity market, and caches it in our database.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was not able to use the polygon API due to {\"status\":\"NOT_AUTHORIZED\",\"request_id\":\"c40154331989627ea57a01daf7e374f2\",\"message\":\"Attempted to request today's data before end of day. Please upgrade your plan at https://polygon.io/pricing\"}; using a random number\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "63.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from market import get_share_price\n",
    "get_share_price(\"AAPL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no rate limiting concerns!\n",
    "\n",
    "for i in range(1000):\n",
    "    get_share_price(\"AAPL\")\n",
    "get_share_price(\"AAPL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And I've made this into an MCP Server\n",
    "\n",
    "Just as we did with accounts.py; see `market_server.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"command\": \"uv\", \"args\": [\"run\", \"market_server.py\"]}\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=60) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "mcp_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's try it out!\n",
    "\n",
    "Hopefully gpt-4o-mini is smart enough to know that the symbol for Apple is AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You answer questions about the stock market.\"\n",
    "request = \"What's the share price of Apple?\"\n",
    "model = \"gpt-4.1-mini\"\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=60) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polygon.io Part 2: Paid Plan - Totally Optional!\n",
    "\n",
    "If you are interested, you can subscribe to the monthly plan to get more up to date market data, and unlimited API calls.\n",
    "\n",
    "If you do wish to do this, then it also makes sense to use the full MCP server that Polygon.io has released, to take advantage of all their functionality.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params = {\"command\": \"uvx\",\n",
    "          \"args\": [\"--from\", \"git+https://github.com/polygon-io/mcp_polygon@v0.1.0\", \"mcp_polygon\"],\n",
    "          \"env\": {\"POLYGON_API_KEY\": polygon_api_key}\n",
    "          }\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=60) as server:\n",
    "    mcp_tools = await server.list_tools()\n",
    "mcp_tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wow that's a lot of tools!\n",
    "\n",
    "Let's try them out - hopefully the sheer number of tools doesn't overwhelm gpt-4o-mini!\n",
    "\n",
    "With the $29 monthly plan, we don't have access to some of the APIs, so I've needed to specify which APIs can be called.\n",
    "\n",
    "If you've splashed out on a bigger plan, feel free to remove my extra constraint.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"You answer questions about the stock market.\"\n",
    "request = \"What's the share price of Apple? Use your get_snapshot_ticker tool to get the latest price.\"\n",
    "model = \"gpt-4.1-mini\"\n",
    "\n",
    "async with MCPServerStdio(params=params, client_session_timeout_seconds=60) as mcp_server:\n",
    "    agent = Agent(name=\"agent\", instructions=instructions, model=model, mcp_servers=[mcp_server])\n",
    "    with trace(\"conversation\"):\n",
    "        result = await Runner.run(agent, request)\n",
    "    display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up your .env file\n",
    "\n",
    "If you do decide to have a paid plan, please add this to your .env file to indicate:\n",
    "\n",
    "`POLYGON_PLAN=paid`\n",
    "\n",
    "And if you decide to go all the way for the realtime API, then please do:\n",
    "\n",
    "`POLYGON_PLAN=realtime`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "polygon_plan = os.getenv(\"POLYGON_PLAN\")\n",
    "is_paid_polygon = polygon_plan == \"paid\"\n",
    "is_realtime_polygon = polygon_plan == \"realtime\"\n",
    "\n",
    "if is_paid_polygon:\n",
    "    print(\"You've chosen to subscribe to the paid Polygon plan, so the code will look at prices on a 15 min delay\")\n",
    "elif is_realtime_polygon:\n",
    "    print(\"Wowzer - you've chosen to subscribe to the realtime Polygon plan, so the code will look at realtime prices\")\n",
    "else:\n",
    "    print(\"According to your .env file, you've chosen to subscribe to the free Polygon plan, so the code will look at EOD prices\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## And that's it for today!\n",
    "\n",
    "I've removed the part of this lab that uses the \"Financial Datasets\" mcp server, because it's inferior - more expensive with fewer APIs.\n",
    "\n",
    "And this way we get to use the same provider for Free and Paid APIs.\n",
    "\n",
    "But if you want to see the code, just look in the git history for a prior version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercises</h2>\n",
    "            <span style=\"color:#ff7800;\">Explore MCP server marketplaces and integrate your own, using all 3 approaches.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
