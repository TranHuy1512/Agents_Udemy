{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 2 Day 1\n",
    "\n",
    "And now! Our first look at OpenAI Agents SDK\n",
    "\n",
    "You won't believe how lightweight this is.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/tools.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">The OpenAI Agents SDK Docs</h2>\n",
    "            <span style=\"color:#00bfff;\">The documentation on OpenAI Agents SDK is really clear and simple: <a href=\"https://openai.github.io/openai-agents-python/\">https://openai.github.io/openai-agents-python/</a> and it's well worth a look.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace\n",
    "from openai import AsyncOpenAI\n",
    "from agents import OpenAIChatCompletionsModel\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The usual starting point\n",
    "\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom model\n",
    "BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "MODEL_NAME='gemini-2.0-flash'\n",
    "\n",
    "gemini_client = AsyncOpenAI(base_url=BASE_URL, api_key=os.getenv(\"GOOGLE_API_KEY\"))\n",
    "custom_model = OpenAIChatCompletionsModel(model=MODEL_NAME, openai_client=gemini_client)  \n",
    "\n",
    "# Make an agent with name, instructions, model\n",
    "agent = Agent(name=\"Jokester\", instructions=\"You are a joke teller\", model=custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the autonomous AI agent cross the road?\n",
      "\n",
      "... Because its objective function told it to optimize for pedestrian traversal efficiency, even if it meant temporarily disrupting the flow of vehicular traffic and slightly increasing the potential for existential dread in nearby squirrels. \n",
      "\n",
      "(Okay, maybe that's more of a bleak observation than a joke. Here's another, shorter one...)\n",
      "\n",
      "Why was the autonomous AI agent bad at dating?\n",
      "\n",
      "... It kept trying to optimize for a compatible personality using a dataset of 10 million dating profiles, and ended up ghosting everyone because it was convinced someone better was always just around the corner.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is not set, skipping trace export\n"
     ]
    }
   ],
   "source": [
    "# Run the joke with Runner.run(agent, prompt) then print final_output\n",
    "\n",
    "with trace(\"Telling a joke\"):\n",
    "    result = await Runner.run(agent, \"Tell a joke about Autonomous AI Agents\")\n",
    "    print(result.final_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now go and look at the trace\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "\n",
    "# logging.basicConfig(filename=\"gemini_logs.log\", level=logging.INFO)\n",
    "\n",
    "# def custom_trace(message):\n",
    "#     logging.info(f\"TRACE: {message}\")\n",
    "\n",
    "# # Gọi hàm trace của bạn\n",
    "# custom_trace(\"Telling a joke\")\n",
    "\n",
    "# # Tiếp tục với mã của bạn\n",
    "# result = await Runner.run(agent, \"Tell a joke about Autonomous AI Agents\")\n",
    "# print(result.final_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
